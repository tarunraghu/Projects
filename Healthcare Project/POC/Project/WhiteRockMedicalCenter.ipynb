{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEALTHCARE PROJECT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `description` cannot be resolved. Did you mean one of the following? [`description,code|1,code|1|type,code|2,code|2|type,code|3,code|3|type,code|4,code|4|type,billing_class,setting,drug_unit_of_measurement,drug_type_of_measurement,standard_charge|gross,standard_charge|discounted_cash,payer_name,plan_name,modifiers,standard_charge|negotiated_dollar,standard_charge|negotiated_percentage,standard_charge|negotiated_algorithm,estimated_amount,standard_charge|min,standard_charge|max,standard_charge|methodology,additional_generic_notes`].;\n'Project ['description, 'code|1, 'payer_name, 'plan_name, 'standard_charge|negotiated dollar, 'standard_charge|min, 'standard_charge|max]\n+- Relation [description,code|1,code|1|type,code|2,code|2|type,code|3,code|3|type,code|4,code|4|type,billing_class,setting,drug_unit_of_measurement,drug_type_of_measurement,standard_charge|gross,standard_charge|discounted_cash,payer_name,plan_name,modifiers,standard_charge|negotiated_dollar,standard_charge|negotiated_percentage,standard_charge|negotiated_algorithm,estimated_amount,standard_charge|min,standard_charge|max,standard_charge|methodology,additional_generic_notes#17] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Select the specified columns with backticks for special characters\u001b[39;00m\n\u001b[0;32m     22\u001b[0m columns_to_include \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`code|1`\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpayer_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplan_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`standard_charge|negotiated dollar`\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     23\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`standard_charge|min`\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`standard_charge|max`\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 24\u001b[0m df_subset \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;241m*\u001b[39mcolumns_to_include)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Show the first few rows of the filtered DataFrame\u001b[39;00m\n\u001b[0;32m     27\u001b[0m df_subset\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\sql\\dataframe.py:3229\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[1;34m(self, *cols)\u001b[0m\n\u001b[0;32m   3184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumnOrName\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   3185\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[0;32m   3186\u001b[0m \n\u001b[0;32m   3187\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3227\u001b[0m \u001b[38;5;124;03m    +-----+---+\u001b[39;00m\n\u001b[0;32m   3228\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3229\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jcols(\u001b[38;5;241m*\u001b[39mcols))\n\u001b[0;32m   3230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `description` cannot be resolved. Did you mean one of the following? [`description,code|1,code|1|type,code|2,code|2|type,code|3,code|3|type,code|4,code|4|type,billing_class,setting,drug_unit_of_measurement,drug_type_of_measurement,standard_charge|gross,standard_charge|discounted_cash,payer_name,plan_name,modifiers,standard_charge|negotiated_dollar,standard_charge|negotiated_percentage,standard_charge|negotiated_algorithm,estimated_amount,standard_charge|min,standard_charge|max,standard_charge|methodology,additional_generic_notes`].;\n'Project ['description, 'code|1, 'payer_name, 'plan_name, 'standard_charge|negotiated dollar, 'standard_charge|min, 'standard_charge|max]\n+- Relation [description,code|1,code|1|type,code|2,code|2|type,code|3,code|3|type,code|4,code|4|type,billing_class,setting,drug_unit_of_measurement,drug_type_of_measurement,standard_charge|gross,standard_charge|discounted_cash,payer_name,plan_name,modifiers,standard_charge|negotiated_dollar,standard_charge|negotiated_percentage,standard_charge|negotiated_algorithm,estimated_amount,standard_charge|min,standard_charge|max,standard_charge|methodology,additional_generic_notes#17] csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Initialize a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"WhiteRockMedicalCenter Data Processing\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Define the file path\n",
    "file_path = r'C:\\Users\\tarun\\Documents\\Semester 4\\Analytics Practicum\\POC\\WhiteRockMedicalCenter.csv'\n",
    "\n",
    "\n",
    "\n",
    "# Read in data with tab delimiter\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"sep\", \"\\t\") \\\n",
    "    .load(file_path)\n",
    "\n",
    "# Select the specified columns with backticks for special characters\n",
    "columns_to_include = [\"description\", \"`code|1`\", \"payer_name\", \"plan_name\", \"`standard_charge|negotiated dollar`\",\n",
    "                      \"`standard_charge|min`\", \"`standard_charge|max`\"]\n",
    "df_subset = df.select(*columns_to_include)\n",
    "\n",
    "# Show the first few rows of the filtered DataFrame\n",
    "df_subset.show()\n",
    "\n",
    "# Rename the columns\n",
    "df_renamed = df_subset.withColumnRenamed(\"description\", \"billing_description\") \\\n",
    "                      .withColumnRenamed(\"`code|1`\", \"billing_code\") \\\n",
    "                      .withColumnRenamed(\"payer_name\", \"insurance_provider\") \\\n",
    "                      .withColumnRenamed(\"plan_name\", \"insurance_plan\") \\\n",
    "                      .withColumnRenamed(\"`standard_charge|negotiated dollar`\", \n",
    "                                         \"gross_standard_charges\") \\\n",
    "                      .withColumnRenamed(\"`standard_charge|min`\", \n",
    "                                         \"min_standard_charges\") \\\n",
    "                      .withColumnRenamed(\"`standard_charge|max`\",\n",
    "                                         \"max_standard_charges\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['description',\n",
       " 'code|1',\n",
       " 'code|1|type',\n",
       " 'code|2',\n",
       " 'code|2|type',\n",
       " 'code|3',\n",
       " 'code|3|type',\n",
       " 'code|4',\n",
       " 'code|4|type',\n",
       " 'billing_class',\n",
       " 'setting',\n",
       " 'drug_unit_of_measurement',\n",
       " 'drug_type_of_measurement',\n",
       " 'standard_charge|gross',\n",
       " 'standard_charge|discounted_cash',\n",
       " 'payer_name',\n",
       " 'plan_name',\n",
       " 'modifiers',\n",
       " 'standard_charge|negotiated_dollar',\n",
       " 'standard_charge|negotiated_percentage',\n",
       " 'standard_charge|negotiated_algorithm',\n",
       " 'estimated_amount',\n",
       " 'standard_charge|min',\n",
       " 'standard_charge|max',\n",
       " 'standard_charge|methodology',\n",
       " 'additional_generic_notes']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column \"hospital name\" with value \"UCLA_Resnick\"\n",
    "df_final = df_renamed.withColumn(\"hospital_name\", lit(\"White Rock Memorial Center\"))\n",
    "\n",
    "# Show the first few rows of the final DataFrame\n",
    "df_final.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Assuming df_renamed is your DataFrame\n",
    "df_final = df_renamed.withColumn(\"hospital_name\", lit(\"White Rock Memorial Center\"))\n",
    "\n",
    "# Filter rows where gross_standard_charges is \"Commercial\"\n",
    "df_filtered = df_final.filter(df_final.gross_standard_charges == \"Commercial\")\n",
    "\n",
    "# Show the first few rows of the filtered DataFrame\n",
    "df_filtered.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
